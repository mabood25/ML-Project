# TITANIC

#dftrainr = raw
#dftrainm = modificado tipos de variables


## 1. Install and Import

! pip install ydata-profiling

! pip install matplotlib

!pip install pycaret

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import numpy as np
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report


dftrainr = pd.read_csv(r'train.csv')
dftestr = pd.read_csv(r'test.csv')

## 2. EDA

dftrainr.shape


dftrainr.describe()

dftrainr.info()

from ydata_profiling import ProfileReport

profile = ProfileReport(dftrainr)
profile.to_file("ydata-profiling EDA Titanic_X.html")

dftrainr_boxplot = dftrainr.dropna(subset=['Age', 'Survived'])

plt.figure(figsize=(10, 6))
sns.boxplot(x='Survived', y='Age', data=dftrainr_boxplot)

plt.title('Boxplots de Edades por Survived')
plt.show()

## 3. Data Processing

dftrainl = dftrainr.copy()

### Imputar (o eliminar) faltantes de Embarked

dftrainl.loc[dftrainl['PassengerId'] == 62, 'Embarked'] = 'S'
dftrainl.loc[dftrainl['PassengerId'] == 830, 'Embarked'] = 'S'

### Eliminar Columnas

dftrainl = dftrainl.drop(['Cabin', 'Name', 'Ticket'],  axis=1)

### Cambiar tipo: Embarked (a dummy)

# dftrainr['Embarked'] = dftrainr['Embarked'].astype('category') 

dftrainl = pd.get_dummies(dftrainl, columns=['Embarked'], prefix='Embarked')

### Cambiar tipo: Pclass a dummy

# Pclass a Categórica (la codificación ordinal ya está inherente en 1,2,3)
# dftrainr['Pclass'] = dftrainr['Pclass'].astype('category')
dftrainl = pd.get_dummies(dftrainl, columns=['Pclass'], prefix='Pclass')

### Cambiar tipo: Sex a dummy (one-hot)

# dftrainr['Sex'] = dftrainr['Sex'].map({'male': 0, 'female': 1})
dftrainl = pd.get_dummies(dftrainl, columns=['Sex'], prefix='Sex')

### Cambiar tipo: para modelo_survived uso  bool / para modelo_age uso dummy

dftrainm = dftrainl.copy()
dftrainm['Survived'] = dftrainm['Survived'].astype(bool) # 0=False

dftrainl = pd.get_dummies(dftrainl, columns=['Survived'], prefix='Survived')

### Imputar (o eliminar) faltantes de Age

dftrainl[dftrainl['Age'].isnull()].head(5)

dftrainr[dftrainr['Age'] < 1]

#### Model_Age: Winner

# Crear conjuntos de entrenamiento y prueba
age_train = dftrainl.dropna(subset=['Age'])
age_test = dftrainl[dftrainl['Age'].isnull()]

# Seleccionar características relevantes para el modelo
features = ['SibSp', 'Fare', 'Sex_female', 'Sex_male', "Survived_0", 'Survived_1', 'Pclass_1', 'Pclass_2', 'Pclass_3']

# Dividir los datos en conjunto de entrenamiento y prueba
X_train = age_train[features]
y_train = age_train['Age']
X_test = age_test[features]

# Inicializar y entrenar el modelo predictivo
model = LinearRegression()
model.fit(X_train, y_train)

# Predecir edades faltantes
predicted_ages = model.predict(X_test)

# Llenar valores faltantes con predicciones
dftrainm.loc[dftrainm['Age'].isnull(), 'Age'] = predicted_ages

dftrainm['Age'] = dftrainm['Age'].astype('float64')
passenger_ids_to_check = [6, 18, 20, 27, 29, 79]
dftrainm[dftrainm['PassengerId'].isin(passenger_ids_to_check)]
#los valores < 1 quedan con predicción 0

dftrainm['Age'].isnull().sum()

#Guardar DF para DSSW
dftrainm.to_csv('dftrainm.csv', index=False)

#### Performance Test: model_age

# Crear conjuntos de entrenamiento y prueba
age_train = dftrainl.dropna(subset=['Age'])
age_test = dftrainl[dftrainl['Age'].isnull()]

# Seleccionar características relevantes para el modelo
features = ['SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', "Survived_0", 'Survived_1', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3']

# Dividir los datos en conjunto de entrenamiento y prueba
X_train = age_train[features]
y_train = age_train['Age']
X_test = age_test[features]

# Inicializar y entrenar el modelo predictivo
model = LinearRegression()
model.fit(X_train, y_train)

# Predecir edades faltantes
predicted_ages = model.predict(X_test)

# Calcular métricas en el conjunto de entrenamiento
mae_train = mean_absolute_error(y_train, model.predict(X_train))
mse_train = mean_squared_error(y_train, model.predict(X_train))
rmse_train = np.sqrt(mse_train)
r2_train = r2_score(y_train, model.predict(X_train))

# Imprimir resultados
print(f'MAE en el conjunto de entrenamiento: {mae_train}')
print(f'MSE en el conjunto de entrenamiento: {mse_train}')
print(f'RMSE en el conjunto de entrenamiento: {rmse_train}')
print(f'R² en el conjunto de entrenamiento: {r2_train}')

# Agregar una constante al conjunto de características
X_train = sm.add_constant(X_train)

# Inicializar el modelo de Statsmodels
model_sm = sm.OLS(y_train, X_train)

# Ajustar el modelo
results = model_sm.fit()

# Imprimir los resultados de los p-values
print(results.summary())

# este es mejor

# Crear conjuntos de entrenamiento y prueba
age_train = dftrainl.dropna(subset=['Age'])
age_test = dftrainl[dftrainl['Age'].isnull()]

# Seleccionar características relevantes para el modelo
features = ['SibSp', 'Fare', 'Sex_female', 'Sex_male', "Survived_0", 'Survived_1', 'Pclass_1', 'Pclass_2', 'Pclass_3']

# Dividir los datos en conjunto de entrenamiento y prueba
X_train = age_train[features]
y_train = age_train['Age']
X_test = age_test[features]

# Inicializar y entrenar el modelo predictivo
model = LinearRegression()
model.fit(X_train, y_train)

# Predecir edades faltantes
predicted_ages = model.predict(X_test)

# Calcular métricas en el conjunto de entrenamiento
mae_train = mean_absolute_error(y_train, model.predict(X_train))
mse_train = mean_squared_error(y_train, model.predict(X_train))
rmse_train = np.sqrt(mse_train)
r2_train = r2_score(y_train, model.predict(X_train))

# Imprimir resultados
print(f'MAE en el conjunto de entrenamiento: {mae_train}')
print(f'MSE en el conjunto de entrenamiento: {mse_train}')
print(f'RMSE en el conjunto de entrenamiento: {rmse_train}')
print(f'R² en el conjunto de entrenamiento: {r2_train}')

# Agregar una constante al conjunto de características
X_train = sm.add_constant(X_train)

# Inicializar el modelo de Statsmodels
model_sm = sm.OLS(y_train, X_train)

# Ajustar el modelo
results = model_sm.fit()

# Imprimir los resultados de los p-values
print(results.summary())

#### Otros clálculos

# Convertir edades a valores enteros (si lo deseas)


#Normaliza o estandariza las variables numéricas si es necesario.

#Título mr, mrs en el nombre
# Extraer títulos de los nombres y convertir 'Name' a categoría
dftrainr['Title'] = dftrainr['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
dftrainr['Name'] = dftrainr['Name'].astype('category')

# Verificar el cambio
print(dftrainr['Name'].dtype)

#edad <1 año

#llos que viajaron solos tenían más o menos probabilidad de sobrevivir

#Clean Overview
dftrainc.describe()

## 4. Model_survived

### Modelo Ganador

y = dftrainm['Survived']
x = dftrainm[['PassengerId', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male']]

#Train-Test Split
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

#Reglog
from sklearn.linear_model import LogisticRegression
reglog=LogisticRegression()
reglog.fit(x_train, y_train)

#Predicción del Modelo
predict=reglog.predict(x_test)

#### Model Testing

###### --> P-Value

# Crear Df para p_value, porque da problemas. parece que cuando hago el código para pvalue no puedo poner la que usaré de referencia con las categóricas
#Descubrí que hacer esto no se neceista. Con dftrainm se puede para directamente a sacar Pvalue, solo que debo recordar eliminar 1 de las que que me salen como categóricas 
columnas_dftrainm = dftrainm[['PassengerId', 'Survived', 'Age', 'SibSp', 'Parch', 'Fare']]
columnas_dftrainr = dftrainr[['Pclass', 'Sex', 'Embarked']]
dftrain_pvalue = pd.concat([columnas_dftrainr, columnas_dftrainm], axis=1)


dftrain_pvalue['Embarked'] = dftrain_pvalue['Embarked'].astype('category')
dftrain_pvalue.loc[dftrain_pvalue['PassengerId'] == 62, 'Embarked'] = 'S'
dftrain_pvalue.loc[dftrain_pvalue['PassengerId'] == 830, 'Embarked'] = 'S'

# Eliminar una categoría de 'Embarked'
dftrain_pvalue = pd.get_dummies(dftrain_pvalue, columns=['Embarked'], drop_first=True)
dftrain_pvalue = pd.get_dummies(dftrain_pvalue, columns=['Pclass'], drop_first=True)
dftrain_pvalue = pd.get_dummies(dftrain_pvalue, columns=['Sex'], drop_first=True)


# P-Value
import statsmodels.api as sm

# Definir variables dependientes e independientes
y = dftrain_pvalue['Survived']
X = dftrain_pvalue[['Embarked_Q', 'Embarked_S', 'Age', 'SibSp', 'Parch', 'Fare', 'Pclass_2', 'Pclass_3', 'Sex_male']]

# Agregar una constante a las variables independientes
X_with_constant = sm.add_constant(X)

# Inicializar el modelo de regresión logística
logit_model = sm.Logit(y, X_with_constant)

# Ajustar el modelo
results = logit_model.fit()

# Obtener los p-values
p_values = results.pvalues

# Mostrar los resultados
print('\nP-values:')
print(p_values)

#### Model #1 - Reglog: All Variables

dftrainm.isnull().sum()

dftrainm[0:11]

dftrainm.shape


891*0.33
#295

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Define variables
y_target = dftrainm['Survived']
X_features = dftrainm[['PassengerId', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male']]

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=.3333, random_state=42)

# Logistic Regression Model
reglog = LogisticRegression()
reglog.fit(X_train, y_train)

# Prediction
predict = reglog.predict(X_test)

# Define Metrics
accuracy = accuracy_score(y_test, predict)
precision = precision_score(y_test, predict)
recall = recall_score(y_test, predict)
f1 = f1_score(y_test, predict)
conf_matrix = confusion_matrix(y_test, predict)
classification_rep = classification_report(y_test, predict)

# Print Metrics
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

# Confusion Matrix and Classification Report
print('\nConfusion Matrix:')
print(pd.DataFrame(conf_matrix, columns=['Predicted No', 'Predicted Yes'], index=['Actual No', 'Actual Yes']))
print('\nClassification Report:')
print(classification_rep)

#### Model #2 - Reglog: Variables considerando p-value significativo

# Define variables
y_target = dftrainm['Survived']
X_features = dftrainm[['PassengerId', 'SibSp','Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male']]

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3333, random_state=42)

# Logistic Regression Model
reglog = LogisticRegression()
reglog.fit(X_train, y_train)

# Prediction
predict = reglog.predict(X_test)

# Define Metrics
accuracy = accuracy_score(y_test, predict)
precision = precision_score(y_test, predict)
recall = recall_score(y_test, predict)
f1 = f1_score(y_test, predict)
conf_matrix = confusion_matrix(y_test, predict)
classification_rep = classification_report(y_test, predict)

# Print Metrics
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

# Confusion Matrix and Classification Report
print('\nConfusion Matrix:')
print(pd.DataFrame(conf_matrix, columns=['Predicted No', 'Predicted Yes'], index=['Actual No', 'Actual Yes']))
print('\nClassification Report:')
print(classification_rep)

#### Model #3 - pycaret: model testing

from pycaret.classification import *

setup = setup(data=dftrainm,
              target="Survived",
              numeric_features=['SibSp', 'Parch', 'Fare'],
              categorical_features=['Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male'],
              ignore_features=['PassengerId'])

models()

best = compare_models(sort='Accuracy')

modelo = create_model("lr")

evaluate_model(modelo)

tuned_model

tuned_model = tune_model(modelo, n_iter=5)

evaluate_model(tuned_model)

#Note:
#Precision: is the ratio of correctly predicted possitive observations to the total predicted positive observations
#Recall: is the ratio of correctly predicted possitive observations to the alll observations in actual class F1 score
#F1 score: is the weighted average of Precision and Recall
